{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j19dOQYnRzX"
      },
      "source": [
        "# MISTRAL OCR PDF to MD Translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä¾†æºèªªæ˜\n",
        "\n",
        "æœ¬ Notebook ä¿®æ”¹è‡ª Mistral å®˜æ–¹ç¯„ä¾‹ï¼š\n",
        "\n",
        "- åŸå§‹æ–‡ä»¶èªªæ˜ï¼š[https://docs.mistral.ai/capabilities/document/](https://docs.mistral.ai/capabilities/document/)\n",
        "- åŸå§‹ Colab Notebookï¼š[https://colab.research.google.com/github/mistralai/cookbook/blob/main/mistral/ocr/structured_ocr.ipynb](https://colab.research.google.com/github/mistralai/cookbook/blob/main/mistral/ocr/structured_ocr.ipynb)\n",
        "\n",
        "> æœ¬ Notebook ç‚ºå€‹äººå­¸ç¿’èˆ‡å¯¦é©—ç”¨é€”æ‰€åšä¿®æ”¹ï¼Œéå®˜æ–¹ç‰ˆæœ¬ã€‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PDF Mistral OCR åŒ¯å‡ºå·¥å…·\n",
        "\n",
        "æœ¬ Notebook å¯å°‡ PDF æ–‡ä»¶è‡ªå‹•åŒ–è½‰æ›ç‚º Markdown æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹æµç¨‹ï¼š\n",
        "\n",
        "1. ä½¿ç”¨ **Mistral OCR** æ¨¡å‹è¾¨è­˜ PDF å…§æ–‡èˆ‡åœ–ç‰‡\n",
        "2. å°‡è¾¨è­˜çµæœçµ„æˆå«åœ–ç‰‡çš„ Markdown æª”\n",
        "3. ä½¿ç”¨ **Gemini** æ¨¡å‹å°‡è‹±æ–‡å…§å®¹ç¿»è­¯ç‚º**å°ç£ç¹é«”ä¸­æ–‡**\n",
        "4. åŒ¯å‡º Markdown æª”ï¼ˆåŸæ–‡ç‰ˆ + ç¿»è­¯ç‰ˆï¼‰èˆ‡å°æ‡‰åœ–ç‰‡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AiErfi7ne9g"
      },
      "outputs": [],
      "source": [
        "from mistralai import Mistral\n",
        "from mistralai.models import OCRResponse, ImageURLChunk, DocumentURLChunk\n",
        "from IPython.display import Markdown, display\n",
        "from pathlib import Path\n",
        "import base64, os, json\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv  # âœ… è¦å®‰è£ python-dotenv\n",
        "\n",
        "load_dotenv()  # ğŸ‘ˆ é€™è¡Œæœƒè‡ªå‹•è®€å– .env ä¸­çš„ key\n",
        "\n",
        "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"âŒ æ‰¾ä¸åˆ° MISTRAL_API_KEYï¼Œè«‹æª¢æŸ¥ .env æ˜¯å¦æ­£ç¢ºè¨­ç½®ã€‚\")\n",
        "\n",
        "client = Mistral(api_key=api_key)\n",
        "\n",
        "# å»ºç«‹æš«æ™‚åœ–ç‰‡è³‡æ–™å¤¾ï¼ˆå¾Œé¢æœƒç”¨è‡ªå‹•å‘½åæ›¿ä»£ï¼‰\n",
        "os.makedirs(\"images\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGjpNjMlnhNa",
        "outputId": "fd665fac-81aa-4b5a-81aa-a99d281ad55e"
      },
      "outputs": [],
      "source": [
        "pdf_dir = Path(\".\")  # æˆ–æŒ‡å®šè³‡æ–™å¤¾\n",
        "pdf_files = sorted([f for f in pdf_dir.glob(\"*.pdf\")])\n",
        "\n",
        "if not pdf_files:\n",
        "    raise FileNotFoundError(\"âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½• PDF æª”æ¡ˆï¼Œè«‹ç¢ºèªæ”¾åœ¨æ­£ç¢ºè³‡æ–™å¤¾ä¸­ã€‚\")\n",
        "\n",
        "print(\"ğŸ“š å¯ç”¨çš„ PDF æª”æ¡ˆï¼š\")\n",
        "for i, f in enumerate(pdf_files):\n",
        "    print(f\"  [{i+1}] {f.name}\")\n",
        "\n",
        "choice = input(\"ğŸ‘‰ è«‹è¼¸å…¥è¦è™•ç†çš„æª”æ¡ˆç·¨è™Ÿï¼š \").strip()\n",
        "pdf_file = pdf_files[int(choice)-1]\n",
        "filename_stem = pdf_file.stem\n",
        "\n",
        "print(f\"âœ… å·²é¸æ“‡ï¼š{pdf_file}\")\n",
        "# ä¸Šå‚³åˆ° mistral\n",
        "uploaded_file = client.files.upload(\n",
        "    file={\n",
        "        \"file_name\": pdf_file.stem,\n",
        "        \"content\": pdf_file.read_bytes(),\n",
        "    },\n",
        "    purpose=\"ocr\"\n",
        ")\n",
        "\n",
        "signed_url = client.files.get_signed_url(file_id=uploaded_file.id, expiry=1)\n",
        "\n",
        "# OCR åˆ†æ PDF\n",
        "pdf_response = client.ocr.process(\n",
        "    document=DocumentURLChunk(document_url=signed_url.url),\n",
        "    model=\"mistral-ocr-latest\",\n",
        "    include_image_base64=True\n",
        ")\n",
        "\n",
        "# Convert response to JSON format\n",
        "response_dict = json.loads(pdf_response.model_dump_json())\n",
        "\n",
        "print(json.dumps(response_dict, indent=4)[0:1000]) # check the first 1000 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sBTj2hGVorvi",
        "outputId": "df303fdb-8a95-434f-9360-187196fb769c"
      },
      "outputs": [],
      "source": [
        "from mistralai.models import OCRResponse\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:\n",
        "    \"\"\"\n",
        "    Replace image placeholders in markdown with base64-encoded images.\n",
        "\n",
        "    Args:\n",
        "        markdown_str: Markdown text containing image placeholders\n",
        "        images_dict: Dictionary mapping image IDs to base64 strings\n",
        "\n",
        "    Returns:\n",
        "        Markdown text with images replaced by base64 data\n",
        "    \"\"\"\n",
        "    for img_name, base64_str in images_dict.items():\n",
        "        markdown_str = markdown_str.replace(\n",
        "            f\"![{img_name}]({img_name})\", f\"![{img_name}]({base64_str})\"\n",
        "        )\n",
        "    return markdown_str\n",
        "\n",
        "def get_combined_markdown(ocr_response: OCRResponse) -> str:\n",
        "    \"\"\"\n",
        "    Combine OCR text and images into a single markdown document.\n",
        "\n",
        "    Args:\n",
        "        ocr_response: Response from OCR processing containing text and images\n",
        "\n",
        "    Returns:\n",
        "        Combined markdown string with embedded images\n",
        "    \"\"\"\n",
        "    markdowns: list[str] = []\n",
        "    # Extract images from page\n",
        "    for page in ocr_response.pages:\n",
        "        image_data = {}\n",
        "        for img in page.images:\n",
        "            image_data[img.id] = img.image_base64\n",
        "        # Replace image placeholders with actual images\n",
        "        markdowns.append(replace_images_in_markdown(page.markdown, image_data))\n",
        "\n",
        "    return \"\\n\\n\".join(markdowns)\n",
        "\n",
        "# Display combined markdowns and images\n",
        "display(Markdown(get_combined_markdown(pdf_response)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVd4L47doPJK"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from mistralai.models import TextChunk\n",
        "import time\n",
        "\n",
        "class StructuredOCR(BaseModel):\n",
        "    file_name: str\n",
        "    topics: list[str]\n",
        "    languages: str\n",
        "    ocr_contents: dict\n",
        "\n",
        "def retry_with_backoff(func, retries=5, base_delay=1.5):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            return func()\n",
        "        except Exception as e:\n",
        "            if \"429\" in str(e):\n",
        "                wait_time = base_delay * (2 ** attempt)\n",
        "                print(f\"âš ï¸ API rate limit hit. Retrying in {wait_time:.1f}s...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                raise e\n",
        "    raise RuntimeError(\"âŒ Failed after multiple retries.\")\n",
        "\n",
        "image_ocr_results = {}\n",
        "\n",
        "for page_idx, page in enumerate(pdf_response.pages):\n",
        "    for i, img in enumerate(page.images):\n",
        "        base64_data_url = img.image_base64\n",
        "        file_name = f\"page_{page_idx+1}_img_{i+1}.png\"\n",
        "\n",
        "        def run_ocr_and_parse():\n",
        "            # Step 1: basic OCR\n",
        "            image_response = client.ocr.process(\n",
        "                document=ImageURLChunk(image_url=base64_data_url),\n",
        "                model=\"mistral-ocr-latest\"\n",
        "            )\n",
        "            image_ocr_markdown = image_response.pages[0].markdown\n",
        "\n",
        "            # Step 2: çµæ§‹åŒ– OCR markdown\n",
        "            structured = client.chat.parse(\n",
        "                model=\"pixtral-12b-latest\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": [\n",
        "                            ImageURLChunk(image_url=base64_data_url),\n",
        "                            TextChunk(text=(\n",
        "                                f\"This is the image's OCR in markdown:\\n{image_ocr_markdown}\\n. \"\n",
        "                                \"Convert this into a structured JSON response with the OCR contents in a sensible dictionary.\"\n",
        "                            ))\n",
        "                        ]\n",
        "                    }\n",
        "                ],\n",
        "                response_format=StructuredOCR,\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            structured_data = structured.choices[0].message.parsed\n",
        "            pretty_text = json.dumps(structured_data.ocr_contents, indent=2, ensure_ascii=False)\n",
        "            return pretty_text\n",
        "\n",
        "        try:\n",
        "            result = retry_with_backoff(run_ocr_and_parse, retries=4)\n",
        "            image_ocr_results[(page_idx, img.id)] = result\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed at page {page_idx+1}, image {i+1}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qCKK2duoy72"
      },
      "outputs": [],
      "source": [
        "def insert_ocr_below_images(markdown_str, ocr_img_map, page_idx):\n",
        "    for img_id, ocr_text in ocr_img_map.get(page_idx, {}).items():\n",
        "        markdown_str = markdown_str.replace(\n",
        "            f\"![{img_id}]({img_id})\",\n",
        "            f\"![{img_id}]({img_id})\\n\\n> ğŸ“„ Image OCR Resultï¼š\\n\\n```json\\n{ocr_text}\\n```\"\n",
        "        )\n",
        "    return markdown_str\n",
        "\n",
        "# é‡å»º ocr_by_page\n",
        "ocr_by_page = {}\n",
        "for (page_idx, img_id), ocr_text in image_ocr_results.items():\n",
        "    ocr_by_page.setdefault(page_idx, {})[img_id] = ocr_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IdUnFcfo0vt"
      },
      "outputs": [],
      "source": [
        "def save_images_and_replace_links(markdown_str, images_dict, page_idx, image_folder=\"images\"):\n",
        "    os.makedirs(image_folder, exist_ok=True)\n",
        "    image_id_to_path = {}\n",
        "\n",
        "    for i, (img_id, base64_str) in enumerate(images_dict.items()):\n",
        "        img_bytes = base64.b64decode(base64_str.split(\",\")[-1])\n",
        "        img_path = f\"{image_folder}/page_{page_idx+1}_img_{i+1}.png\"\n",
        "        with open(img_path, \"wb\") as f:\n",
        "            f.write(img_bytes)\n",
        "        image_id_to_path[img_id] = img_path\n",
        "\n",
        "    for img_id, img_path in image_id_to_path.items():\n",
        "        markdown_str = markdown_str.replace(\n",
        "            f\"![{img_id}]({img_id})\", f\"![{img_id}]({img_path})\"\n",
        "        )\n",
        "\n",
        "    return markdown_str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q34NBxOzujLg"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "# âœ… è¼‰å…¥ .env æª”æ¡ˆ\n",
        "load_dotenv()\n",
        "\n",
        "# âœ… è®€å– API é‡‘é‘°\n",
        "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"âŒ æœªåœ¨ .env æ‰¾åˆ° GEMINI_API_KEYï¼Œè«‹ç¢ºèªå·²æ­£ç¢ºè¨­ç½®ã€‚\")\n",
        "\n",
        "# âœ… åˆå§‹åŒ– Gemini client\n",
        "client = genai.Client(api_key=gemini_api_key)\n",
        "\n",
        "SYSTEM_INSTRUCTION = \"\"\"\n",
        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æŠ€è¡“æ–‡ä»¶ç¿»è­¯è€…ã€‚è«‹å°‡æˆ‘æä¾›çš„è‹±æ–‡ Markdown å…§å®¹ç¿»è­¯æˆ**å°ç£ç¹é«”ä¸­æ–‡**ã€‚\n",
        "\n",
        "**æ ¸å¿ƒè¦æ±‚ï¼š**\n",
        "1.  **ç¿»è­¯æ‰€æœ‰è‹±æ–‡æ–‡å­—ï¼š** ä½ çš„ä¸»è¦å·¥ä½œæ˜¯ç¿»è­¯å…§å®¹ä¸­çš„è‹±æ–‡æ•˜è¿°æ€§æ–‡å­—ï¼ˆæ®µè½ã€åˆ—è¡¨ã€è¡¨æ ¼ç­‰ï¼‰ã€‚\n",
        "2.  **ä¿æŒçµæ§‹èˆ‡ç¨‹å¼ç¢¼ä¸è®Šï¼š**\n",
        "    * **ä¸è¦**æ›´æ”¹ä»»ä½• Markdown æ¨™è¨˜ï¼ˆå¦‚ `#`, `*`, `-`, `[]()`, `![]()`, ``` ```, ` `` `, `---`ï¼‰ã€‚\n",
        "    * **ä¸è¦**ç¿»è­¯æˆ–ä¿®æ”¹ç¨‹å¼ç¢¼å€å¡Š (``` ... ```) å’Œè¡Œå…§ç¨‹å¼ç¢¼ (`code`) è£¡çš„ä»»ä½•å…§å®¹ã€‚\n",
        "    * è‹¥æœ‰ JSONï¼Œ**ä¸è¦**æ›´æ”¹éµï¼ˆkeyï¼‰ï¼Œåƒ…ç¿»è­¯å­—ä¸²å€¼ï¼ˆvalueï¼‰ã€‚\n",
        "3.  **è™•ç†å°ˆæœ‰åè©ï¼š** å°æ–¼æ™®éæ¥å—çš„è‹±æ–‡æŠ€è¡“è¡“èªã€ç¸®å¯«æˆ–å°ˆæœ‰åè©ï¼ˆä¾‹å¦‚ API, SDK, CPU, Google, Python ç­‰ï¼‰ï¼Œå‚¾å‘æ–¼**ä¿ç•™è‹±æ–‡åŸæ–‡**ã€‚ä½†è«‹ç¢ºä¿ç¿»è­¯äº†å…¶ä»–æ‰€æœ‰éè¡“èªçš„å¸¸è¦è‹±æ–‡æ–‡å­—ã€‚\n",
        "4.  **ç›´æ¥è¼¸å‡ºçµæœï¼š** è«‹ç›´æ¥å›å‚³ç¿»è­¯å¾Œçš„å®Œæ•´ Markdown æ–‡ä»¶ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¡å¤–èªªæ˜ã€‚\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def translate_markdown_pages(pages):\n",
        "    translated_pages = []\n",
        "\n",
        "    for idx, page in enumerate(pages):\n",
        "        try:\n",
        "            print(f\"ğŸ” æ­£åœ¨ç¿»è­¯ç¬¬ {idx+1} é ...\")\n",
        "\n",
        "            response = client.models.generate_content(\n",
        "                model=\"gemini-2.0-flash\",\n",
        "                config=types.GenerateContentConfig(\n",
        "                    system_instruction=SYSTEM_INSTRUCTION\n",
        "                ),\n",
        "                contents=page\n",
        "            )\n",
        "\n",
        "            translated_md = response.text.strip()\n",
        "            translated_pages.append(translated_md)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ç¿»è­¯ç¬¬ {idx+1} é å¤±æ•—ï¼š{e}\")\n",
        "            translated_pages.append(page)\n",
        "\n",
        "    return translated_pages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "resources": {
            "http://localhost:8080/images_paper2/page_2_img_1.png": {
              "data": "",
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/images_paper2/page_8_img_1.png": {
              "data": "",
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "ok": false,
              "status": 404,
              "status_text": ""
            }
          }
        },
        "id": "d_qOspnAvRWK",
        "outputId": "8e50c7f3-fa5f-4f19-b1fc-21f60d733162"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "filename_stem = pdf_file.stem\n",
        "\n",
        "markdown_pages = []\n",
        "\n",
        "for page_idx, page in enumerate(pdf_response.pages):\n",
        "    images_dict = {img.id: img.image_base64 for img in page.images}\n",
        "\n",
        "    md = page.markdown\n",
        "    md = insert_ocr_below_images(md, ocr_by_page, page_idx)\n",
        "    image_folder_name = f\"images_{filename_stem}\"\n",
        "    md = save_images_and_replace_links(md, images_dict, page_idx, image_folder=image_folder_name)\n",
        "\n",
        "\n",
        "    markdown_pages.append(md)\n",
        "\n",
        "\n",
        "# âœ… åŸ·è¡Œç¿»è­¯\n",
        "translated_markdown_pages = translate_markdown_pages(markdown_pages)\n",
        "\n",
        "# âœ… çµ„åˆç‚ºå®Œæ•´ markdown å­—ä¸²ï¼ˆä¿ç•™åˆ†é åˆ†éš”ç·šï¼‰\n",
        "final_markdown_translated = \"\\n\\n---\\n\\n\".join(translated_markdown_pages)\n",
        "final_markdown_original = \"\\n\\n---\\n\\n\".join(markdown_pages)\n",
        "\n",
        "# é è¦½ç¿»è­¯ç‰ˆæœ¬\n",
        "display(Markdown(final_markdown_translated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "o5fKPWsu3xgY",
        "outputId": "cd801a85-b410-486e-b2e0-cfd983d790ee"
      },
      "outputs": [],
      "source": [
        "# ğŸ”½ è¨­å®šæª”å\n",
        "translated_md_name = f\"{filename_stem}_translated.md\"\n",
        "original_md_name = f\"{filename_stem}_original.md\"\n",
        "image_folder_name = f\"images_{filename_stem}\"\n",
        "\n",
        "# å„²å­˜ç¿»è­¯å¾Œæª”æ¡ˆ\n",
        "with open(translated_md_name, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_markdown_translated)\n",
        "\n",
        "# å„²å­˜è‹±æ–‡ OCR åŸå§‹æª”æ¡ˆ\n",
        "with open(original_md_name, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_markdown_original)\n",
        "\n",
        "\n",
        "# ä¸‹è¼‰æ‰€æœ‰æª”æ¡ˆ\n",
        "print(f\"âœ… å·²å„²å­˜ç¿»è­¯ç‰ˆï¼š{translated_md_name}\")\n",
        "print(f\"âœ… å·²å„²å­˜åŸå§‹è‹±æ–‡ç‰ˆï¼š{original_md_name}\")\n",
        "print(f\"âœ… åœ–ç‰‡è³‡æ–™å¤¾ï¼š{image_folder_name}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (mistral_ocr)",
      "language": "python",
      "name": "mistral_ocr"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
